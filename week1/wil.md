    첫 주차에는 인공지능, 머신러닝, 딥러닝이 무엇인지에 대한 소개와 인공지능의 학습방법, 데이터를 분리하는 방법과
기초적인 모델들에 대한 설명을 듣는 시간을 가졌다. 위키피디아에 의하면 인공지능은 인간의 학습능력, 추론능력, 지각능력을
인공적으로 구현하려는 컴퓨터 과학의 세부분야 중 하나이고 머신러닝은 컴퓨터가 데이터로부터 패턴을 학습하고, 학습한 내용을 바탕으로
결정을 내리는 기술이며 딥러닝은 인공신경망을 이용해 모델을 학습시키는 방법이라 한다.
    인공지능의 학습방법은 크게 지도학습과 비지도학습으로 나뉘는데 지도학습은 x라는 데이터에 y라는 레이블을 달아서 특징을 학습하도록
하는 학습방법이다. 주로 분류문제와 번역기등 실질적인 답을 구하기 위해 이용된다. 반면 비지도학습은 데이터만 있고 정답이 없는 데이터를
학습시키는 방법으로 clustering 알고리즘과 같은 문제에 이용된다.
    전체 데이터는 모델에 학습에 사용되는 학습 데이터, 모델의 하이퍼파라미터 학습에 사용되는 검증 데이터, 최종적으로 모델을 평가할 때
사용되는 테스트 데이터로 분리된다. 
    기초적인 모델중 Nearest Neighbor Classifier 방식은 지도 학습 알고리즘 중 하나로 어떤 데이터가 주어지면 그 주변의 데이터를 살펴본 뒤
더 많은 데이터가 포함되어 있는 범주로 분류하는 방식이다. 모든 train data를 기억하고 있으며 해당 방식으로 예측을 할 때는 모든 train data
와 비교하여 가장 가까운 train image의 label을 리턴하는 식으로 동작한다. L1 distance: dist = |a?b| 이고 L2 distance: dist =루트(a?b)^2
이다. KNN 알고리즘은 Nearest Neighbor Classifier 방식과 전체적으로 같지만 분류과정에서 가장 가까운 image를 리턴하는게 아닌, K개의 가까운
이미지를 찾고 가장 많이 나온 이미지의 label을 리턴하는 특징이 있다. 그러므로 학습 데이터를 Nearest Neibor Classifier 방식에 적용하면 100%의 정확도가 나오지만 KNN에선 그렇지 않을 수 있다. 정확도를 높이기 위해 L1 dist, L2 dist, K를 몇으로 할지 정해야 하며 Validation data를 가지고 테스트 하여, 가장 높은 정확도가 나오도록 정하면 된다. KNN의 특징으로는 테스트 시간이 정말 길고 Shifted, messed up, darkend 등 이미지를 조금만 변형해도 성능이 떨어진다는 것이다. 마지막으로 선형분류는 입력에 가중치를 부여해 분류를 파라미터적으로 접근하는 방식이다. 선형 분류는 색에 많이 의존하는 경향이 있다.